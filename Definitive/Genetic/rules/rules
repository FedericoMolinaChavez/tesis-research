lstm -> (lstm,dense)
dense -> (end)
rangeLstm -> (2,500)
rangeLayLstm -> (2,32)
optim -> (adam,adagrad,RMSprop,SGD,Adamax,Nadam)
loss -> (categorical_crossentropy,poisson,mean_squared_error)
activation -> (softmax)
ractivation -> (hard_sigmoid,softmax,relu,tanh)
batch -> (2,32)
window -> (11)
learningRate -> (0.001,0.1)
amsgrad -> (optim=adam)
drop -> (0.1,0.5)
rdrop -> (0.1,0.5)
epochs -> (2,100)